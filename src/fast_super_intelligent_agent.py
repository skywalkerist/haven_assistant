#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¿«é€Ÿè¶…çº§æ™ºèƒ½ä½“ - ä¼˜åŒ–ç‰ˆæœ¬çš„ä¸»æ™ºèƒ½ä½“ç³»ç»Ÿ
é‡ç‚¹ä¼˜åŒ–ï¼šå‡å°‘çŠ¶æ€æ£€æŸ¥ã€å†…å­˜ç¼“å­˜ã€æ‰¹é‡å¤„ç†ã€å¼‚æ­¥æ“ä½œ
"""

import os
import sys
import time
import threading
import signal
import io
from typing import Optional, Tuple, Dict, Any
from dataclasses import dataclass
from enum import Enum

# æ·»åŠ å¿…è¦çš„è·¯å¾„
sys.path.append('/home/xuanwu/pyorbbecsdk/examples')
sys.path.append('/home/xuanwu/haven_ws/src')
sys.path.append('/home/xuanwu/snowboy/snowboy-master/examples/Python3')

# å¯¼å…¥è¯­éŸ³å”¤é†’æ¨¡å—
import snowboydecoder

# å¯¼å…¥ä¼˜åŒ–çš„ç»„ä»¶
from fast_memory_agent import FastMemoryAgent
from face_recognition_client import FaceRecognitionClient, FaceRecognitionConfig
from audio_recorder import AudioRecorder
from spark_asr import SparkASR
from voice_cloner import VoiceCloner
from move_controller import MoveController
from openai import OpenAI

# å¯¼å…¥æ€§èƒ½ä¼˜åŒ–å·¥å…·
from performance_utils import (
    PerformanceOptimizer, FastStringProcessor, MemoryCache,
    global_cache, file_cleanup_batch, fast_hash
)
from optimized_config import fast_config, should_skip_check, get_timeout, get_batch_size

class AgentState(Enum):
    """æ™ºèƒ½ä½“çŠ¶æ€æšä¸¾"""
    LISTENING = "listening"
    WAKE_DETECTED = "wake_detected"
    SCANNING = "scanning"
    SEARCHING = "searching"
    CHATTING = "chatting"

@dataclass
class FastSuperAgentConfig:
    """å¿«é€Ÿè¶…çº§æ™ºèƒ½ä½“é…ç½®"""
    # é¢éƒ¨è¯†åˆ«é…ç½®
    face_config: FaceRecognitionConfig = None
    
    # DeepSeek APIé…ç½®
    deepseek_api_key: str = "sk-fdabadb2973b4795b2444da60e75152f"
    deepseek_base_url: str = "https://api.deepseek.com"
    
    # è®°å¿†ç³»ç»Ÿé…ç½®
    memory_file_path: str = "/home/xuanwu/haven_ws/demos/data/memory_tree.json"
    
    # è¯­éŸ³å”¤é†’é…ç½®
    wake_word_model: str = "/home/xuanwu/haven_ws/src/resources/haven.pmdl"
    wake_sensitivity: float = 0.5
    greeting_audio: str = "/home/xuanwu/haven_ws/config/greeting.wav"
    
    # è¯­éŸ³è¯†åˆ«é…ç½®
    asr_app_id: str = "b32f165e"
    asr_api_key: str = "bf4caffa0bd087acc04cd63d0ee27fc5"
    asr_api_secret: str = "MmJiZjQ0NTIzOTdhOWU0ZWY5ZjUyNzI0"

    tts_voice_name: str = "default"
    tts_config_path: str = "/home/xuanwu/haven_ws/config/voices.json"
    tts_text_file: str = "/tmp/tts_text.txt"
    tts_audio_file: str = "/tmp/tts_output.wav"
    
    # æœºå™¨äººç§»åŠ¨é…ç½®
    robot_host: str = "192.168.10.10"
    robot_port: int = 31001
    
    # æœç´¢é…ç½®ï¼ˆä¼˜åŒ–ï¼‰
    search_angle_range: Tuple[int, int] = (-45, 45)  # å‡å°‘æœç´¢èŒƒå›´
    search_step: int = 45  # å¢åŠ æ­¥é•¿
    search_delay: float = fast_config.FACE_RECOGNITION_CONFIG['search_stabilization_time']
    
    # è¯†åˆ«é…ç½®
    recognition_confidence_threshold: float = 0.6
    continuous_scan_interval: float = 0.3  # å‡å°‘æ‰«æé—´éš”
    unknown_user_timeout: float = 3.0  # å‡å°‘è¶…æ—¶æ—¶é—´

class FastSuperIntelligentAgent:
    """
    å¿«é€Ÿè¶…çº§æ™ºèƒ½ä½“ - ä¼˜åŒ–ç‰ˆæœ¬
    """
    
    def __init__(self, config: FastSuperAgentConfig):
        self.config = config
        self.state = AgentState.LISTENING
        self.memory_history = ""
        
        # åˆå§‹åŒ–ä¼˜åŒ–çš„å­ç³»ç»Ÿ
        self.face_system = FaceRecognitionClient(config.face_config)
        self.memory_agent = FastMemoryAgent(
            deepseek_api_key=config.deepseek_api_key,
            deepseek_base_url=config.deepseek_base_url,
            memory_file_path=config.memory_file_path
        )
        
        # åˆå§‹åŒ–DeepSeekå®¢æˆ·ç«¯
        self.deepseek_client = OpenAI(
            api_key=config.deepseek_api_key,
            base_url=config.deepseek_base_url
        )
        
        # åˆå§‹åŒ–TTSç³»ç»Ÿ
        self.voice_cloner = VoiceCloner(
            app_id=config.asr_app_id,
            api_key=config.asr_api_key,
            api_secret=config.asr_api_secret,
            text_file=config.tts_text_file,
            output_file=config.tts_audio_file,
            voice_name=config.tts_voice_name,
            config_path=config.tts_config_path
        )
        
        # åˆå§‹åŒ–ç§»åŠ¨æ§åˆ¶å™¨
        self.move_controller = MoveController(
            host=config.robot_host,
            port=config.robot_port
        )
        self.move_connected = False
        
        # çŠ¶æ€å˜é‡
        self.current_user: Optional[str] = None
        self.current_confidence: float = 0.0
        self.last_recognition_time: float = 0.0
        self.is_running: bool = False
        self.recognition_thread: Optional[threading.Thread] = None
        
        # è¯­éŸ³å”¤é†’ç›¸å…³
        self.wake_detector: Optional[snowboydecoder.HotwordDetector] = None
        self.interrupted: bool = False
        
        # æœç´¢çŠ¶æ€
        self.search_current_angle: int = 0
        self.search_direction: int = 1
        self.search_interrupted: bool = False
        
        # å®šä¹‰å·¥å…·å‡½æ•°
        self.tools = self._define_tools()
        
        # æ€§èƒ½ä¼˜åŒ–ï¼šç¼“å­˜å¸¸ç”¨æ•°æ®
        self._audio_cache = MemoryCache(max_size=20)
        self._response_cache = MemoryCache(max_size=30)
        self._temp_files = []  # æ‰¹é‡æ¸…ç†çš„ä¸´æ—¶æ–‡ä»¶åˆ—è¡¨
        
        print("ğŸ¤– å¿«é€Ÿæ™ºèƒ½ä½“åˆå§‹åŒ–å®Œæˆ")
    
    def _define_tools(self):
        """å®šä¹‰DeepSeekå¯è°ƒç”¨çš„å·¥å…·å‡½æ•°ï¼ˆå®Œæ•´ä¿ç•™ï¼‰"""
        return [
            # äººè„¸è¯†åˆ«å·¥å…·
            {
                "type": "function",
                "function": {
                    "name": "recognize_face",
                    "description": "è¯†åˆ«å½“å‰ç”¨æˆ·çš„äººè„¸",
                    "parameters": {
                        "type": "object",
                        "properties": {},
                    },
                }
            },
            # äººè„¸æ³¨å†Œå·¥å…·
            {
                "type": "function", 
                "function": {
                    "name": "register_face",
                    "description": "æ³¨å†Œæ–°ç”¨æˆ·çš„äººè„¸ï¼Œéœ€è¦ç”¨æˆ·æä¾›å§“å",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "user_name": {
                                "type": "string",
                                "description": "è¦æ³¨å†Œçš„ç”¨æˆ·å§“å",
                            }
                        },
                        "required": ["user_name"]
                    },
                }
            },
            # ç§»åŠ¨ç›¸å…³å·¥å…·ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
            {
                "type": "function",
                "function": {
                    "name": "move_forward",
                    "description": "æœºå™¨äººå‘å‰ç§»åŠ¨æŒ‡å®šè·ç¦»",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "distance": {
                                "type": "number",
                                "description": "å‰è¿›è·ç¦»ï¼Œå•ä½ä¸ºç±³",
                            }
                        },
                        "required": ["distance"]
                    },
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "move_backward", 
                    "description": "æœºå™¨äººå‘åç§»åŠ¨æŒ‡å®šè·ç¦»",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "distance": {
                                "type": "number",
                                "description": "åé€€è·ç¦»ï¼Œå•ä½ä¸ºç±³",
                            }
                        },
                        "required": ["distance"]
                    },
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "turn_left",
                    "description": "æœºå™¨äººå‘å·¦è½¬æŒ‡å®šè§’åº¦",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "angle": {
                                "type": "number",
                                "description": "å·¦è½¬è§’åº¦ï¼Œå•ä½ä¸ºåº¦",
                            }
                        },
                        "required": ["angle"]
                    },
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "turn_right",
                    "description": "æœºå™¨äººå‘å³è½¬æŒ‡å®šè§’åº¦",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "angle": {
                                "type": "number",
                                "description": "å³è½¬è§’åº¦ï¼Œå•ä½ä¸ºåº¦",
                            }
                        },
                        "required": ["angle"]
                    },
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "move_to_location",
                    "description": "æœºå™¨äººç§»åŠ¨åˆ°æŒ‡å®šçš„æ ‡è®°ç‚¹ä½ç½®",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "location_name": {
                                "type": "string",
                                "description": "ç›®æ ‡ä½ç½®çš„æ ‡è®°ç‚¹åç§°",
                            }
                        },
                        "required": ["location_name"]
                    },
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "cancel_move",
                    "description": "å–æ¶ˆå½“å‰æ­£åœ¨æ‰§è¡Œçš„ç§»åŠ¨ä»»åŠ¡",
                    "parameters": {
                        "type": "object",
                        "properties": {},
                    },
                }
            }
        ]
    
    @PerformanceOptimizer.timing_decorator("initialize")
    def initialize(self) -> bool:
        """å¿«é€Ÿåˆå§‹åŒ–ç³»ç»Ÿ"""
        # åˆå§‹åŒ–é¢éƒ¨è¯†åˆ«ç³»ç»Ÿ
        if not self.face_system.initialize():
            print("âŒ é¢éƒ¨è¯†åˆ«ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥")
            return False
        
        # å¯åŠ¨é¢éƒ¨è¯†åˆ«
        if not self.face_system.start_recognition():
            print("âŒ å¯åŠ¨é¢éƒ¨è¯†åˆ«å¤±è´¥")
            return False
        
        # å°è¯•è¿æ¥æœºå™¨äººç§»åŠ¨ç³»ç»Ÿï¼ˆè·³è¿‡è¯¦ç»†æ£€æŸ¥ï¼‰
        if should_skip_check('service_health') or self.move_controller.connect():
            self.move_connected = True
        
        return True
    
    def interrupt_callback(self):
        """ä¸­æ–­å›è°ƒå‡½æ•°"""
        return self.interrupted
    
    def signal_handler(self, sig, frame):
        """ä¿¡å·å¤„ç†å‡½æ•°"""
        self.interrupted = True
    
    def start_voice_wake_listening(self):
        """å¯åŠ¨è¯­éŸ³å”¤é†’ç›‘å¬"""
        if not should_skip_check('audio_file_exists') and not os.path.exists(self.config.wake_word_model):
            print(f"âŒ å”¤é†’è¯æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {self.config.wake_word_model}")
            return False
        
        print('ğŸ§ æ­£åœ¨ç›‘å¬è¯­éŸ³å”¤é†’è¯...')
        
        # è®¾ç½®ä¿¡å·å¤„ç†
        signal.signal(signal.SIGINT, self.signal_handler)
        
        try:
            # åˆ›å»ºæ£€æµ‹å™¨
            self.wake_detector = snowboydecoder.HotwordDetector(
                self.config.wake_word_model,
                sensitivity=self.config.wake_sensitivity
            )
            
            # å¼€å§‹ç›‘å¬
            self.wake_detector.start(
                detected_callback=self._wake_word_callback,
                interrupt_check=self.interrupt_callback,
                sleep_time=0.03
            )
            
        except Exception as e:
            print(f"âŒ è¯­éŸ³å”¤é†’ç›‘å¬å¯åŠ¨å¤±è´¥: {e}")
            return False
        finally:
            if self.wake_detector:
                self.wake_detector.terminate()
        
        return True
    
    def _wake_word_callback(self):
        """å”¤é†’è¯æ£€æµ‹å›è°ƒå‡½æ•°"""
        print("ğŸŒ… æ£€æµ‹åˆ°å”¤é†’è¯ï¼")
        
        # åœæ­¢å”¤é†’è¯æ£€æµ‹
        if self.wake_detector:
            self.wake_detector.terminate()
        
        self.state = AgentState.WAKE_DETECTED
        
        # æ’­æ”¾æ‹›å‘¼è¯­éŸ³ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        self._play_greeting_if_exists()
        
        # å¼€å§‹é¢éƒ¨è¯†åˆ«å’Œç”¨æˆ·äº¤äº’æµç¨‹
        self._handle_wake_detected()
        
        # å®Œæˆäº¤äº’åé‡æ–°å¼€å§‹ç›‘å¬
        self.state = AgentState.LISTENING
        self.start_voice_wake_listening()
    
    def _play_greeting_if_exists(self):
        """æ’­æ”¾æ‹›å‘¼è¯­éŸ³ï¼ˆè·³è¿‡æ£€æŸ¥ä¼˜åŒ–ï¼‰"""
        if should_skip_check('audio_file_exists') or os.path.exists(self.config.greeting_audio):
            try:
                os.system(f'aplay -f S16_LE -r 16000 -c 1 {self.config.greeting_audio}')
            except:
                pass  # ç®€åŒ–é”™è¯¯å¤„ç†
    
    def _handle_wake_detected(self):
        """å¤„ç†å”¤é†’æ£€æµ‹åçš„æµç¨‹"""
        try:
            # è·³è¿‡é‡å¤çš„é¢éƒ¨è¯†åˆ«å¯åŠ¨æ£€æŸ¥
            if not should_skip_check('service_health'):
                if not self.face_system.start_recognition():
                    print("âŒ å¯åŠ¨é¢éƒ¨è¯†åˆ«å¤±è´¥")
                    return
            
            # å¼€å§‹è¯†åˆ«ç”¨æˆ·
            user_name = self._identify_user_with_fast_search()
            
            if user_name and user_name != "Unknown":
                # ä¸ªæ€§åŒ–ç¡®è®¤æç¤º
                self._give_personalized_greeting(user_name)
                
                # å¼€å§‹å¯¹è¯
                self._start_fast_conversation_with_user(user_name)
            else:
                print("ğŸ˜” æœªèƒ½è¯†åˆ«åˆ°æ³¨å†Œç”¨æˆ·")
                
        except Exception as e:
            if not should_skip_check('detailed_validation'):
                print(f"âŒ å”¤é†’å¤„ç†è¿‡ç¨‹å‡ºé”™: {e}")
        finally:
            # åœæ­¢é¢éƒ¨è¯†åˆ«
            self.face_system.stop_recognition()
    
    @PerformanceOptimizer.timing_decorator("give_personalized_greeting")
    def _give_personalized_greeting(self, user_name: str):
        """ç»™å‡ºä¸ªæ€§åŒ–çš„é—®å€™ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰"""
        # ä½¿ç”¨ç¼“å­˜çš„é—®å€™æ–‡æœ¬
        cache_key = f"greeting_{user_name}"
        greeting_text = self._response_cache.get(cache_key)
        
        if greeting_text is None:
            greeting_text = f"{user_name}æ‚¨å¥½ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®åˆ°æ‚¨ï¼Ÿ"
            self._response_cache.put(cache_key, greeting_text)
        
        print(f"ğŸ¤– {greeting_text}")
        
        # ä½¿ç”¨TTSè¯­éŸ³æ’­æ”¾é—®å€™ï¼ˆä¼˜åŒ–I/Oï¼‰
        try:
            if fast_config.FAST_MODE.get('memory_optimization', False):
                # ä½¿ç”¨å†…å­˜è€Œéæ–‡ä»¶
                self._tts_to_memory_and_play(greeting_text)
            else:
                # ä¼ ç»Ÿæ–‡ä»¶æ–¹å¼
                with open(self.config.tts_text_file, 'w', encoding='utf-8') as f:
                    f.write(greeting_text)
                
                self.voice_cloner.speak()
                self.voice_cloner.play_audio()
            
        except Exception as e:
            if not should_skip_check('detailed_validation'):
                print(f"âŒ ä¸ªæ€§åŒ–é—®å€™TTSå¤±è´¥: {e}")
    
    def _tts_to_memory_and_play(self, text: str):
        """TTSåˆ°å†…å­˜å¹¶æ’­æ”¾ï¼ˆé¿å…æ–‡ä»¶I/Oï¼‰"""
        # è¿™é‡Œå¯ä»¥å®ç°å†…å­˜ç‰ˆæœ¬çš„TTSï¼Œæš‚æ—¶ä½¿ç”¨æ–‡ä»¶ç‰ˆæœ¬
        with open(self.config.tts_text_file, 'w', encoding='utf-8') as f:
            f.write(text)
        self.voice_cloner.speak()
        self.voice_cloner.play_audio()
    
    @PerformanceOptimizer.timing_decorator("identify_user_with_fast_search")
    def _identify_user_with_fast_search(self) -> Optional[str]:
        """å¿«é€Ÿè¯†åˆ«ç”¨æˆ·"""
        # ç›´æ¥æ‰«æï¼ˆå‡å°‘æ—¶é—´ï¼‰
        max_direct_scan_time = 1.5  # ä»2.0å‡å°‘åˆ°1.5
        start_time = time.time()
        
        while (time.time() - start_time) < max_direct_scan_time:
            recognized_name, _ = self.face_system.recognize_person()
            if recognized_name and recognized_name != "Unknown":
                return recognized_name
            time.sleep(0.2)
        
        # å¿«é€Ÿæœç´¢æ¨¡å¼
        return self._fast_search_for_user()
    
    def _fast_search_for_user(self) -> Optional[str]:
        """å¿«é€Ÿæœç´¢ç”¨æˆ·ï¼ˆä¼˜åŒ–è§’åº¦å’Œæ—¶é—´ï¼‰"""
        # åªæœç´¢3ä¸ªå…³é”®è§’åº¦ï¼š0Â°, 45Â°, -45Â°
        search_angles = [0, 45, -45]
        
        try:
            for angle in search_angles:
                # è½¬å¤´åˆ°æŒ‡å®šè§’åº¦
                self.face_system.turn_head(angle)
                
                # å‡å°‘ç­‰å¾…æ—¶é—´
                time.sleep(self.config.search_delay)
                
                # å¿«é€Ÿè¯†åˆ«
                start_time = time.time()
                max_recognition_time = 1.5  # ä»2.0å‡å°‘åˆ°1.5ç§’
                
                while (time.time() - start_time) < max_recognition_time:
                    recognized_name, _ = self.face_system.recognize_person()
                    if recognized_name and recognized_name != "Unknown":
                        print(f"ğŸ¯ åœ¨è§’åº¦{angle}Â°å‘ç°ç”¨æˆ·: {recognized_name}")
                        return recognized_name
                    time.sleep(0.3)
                    
            return None
            
        except Exception as e:
            if not should_skip_check('detailed_validation'):
                print(f"âŒ æœç´¢è¿‡ç¨‹å‡ºé”™: {e}")
            return None
        finally:            
            # æœç´¢å®Œæˆï¼Œå›åˆ°æ­£é¢
            self.face_system.return_home()
    
    @PerformanceOptimizer.timing_decorator("start_fast_conversation")
    def _start_fast_conversation_with_user(self, user_name: str):
        """å¿«é€Ÿå¯¹è¯ç³»ç»Ÿ"""
        print(f"ğŸ’¬ å¼€å§‹ä¸ {user_name} çš„è¯­éŸ³å¯¹è¯")
        
        try:
            # å¯åŠ¨å¿«é€Ÿè®°å¿†æ™ºèƒ½ä½“å¯¹è¯
            if not self.memory_agent.start_chat(user_name):
                print("âŒ æ— æ³•å¯åŠ¨å¯¹è¯ç³»ç»Ÿ")
                return
            
            self.state = AgentState.CHATTING
            
            # å¯åŠ¨äººè„¸è·Ÿè¸ªçº¿ç¨‹ï¼ˆå¯¹è¯æœŸé—´ä¿æŒè·Ÿè¸ªï¼‰
            self._start_face_tracking_thread()
            
            # åˆ›å»ºéŸ³é¢‘å½•éŸ³å™¨
            recorder = AudioRecorder()
            
            # print("ğŸ¤ è¯·å¼€å§‹è¯´è¯...")
            
            conversation_count = 0
            max_turns = fast_config.CONVERSATION_CONFIG['max_conversation_turns']
            
            while self.state == AgentState.CHATTING and conversation_count < max_turns:
                try:
                    conversation_count += 1
                    
                    # è¯­éŸ³å½•éŸ³ï¼ˆä½¿ç”¨ä¼˜åŒ–å‚æ•°ï¼‰
                    audio_file = f"/tmp/user_input_{conversation_count}.wav"
                    # print("ğŸ¤ è¯·å¼€å§‹è¯´è¯...")
                    print("ä¼˜åŒ–ã€‚ã€‚ã€‚")
                    
                    recorder.start_dynamic_recording(
                        output_file=audio_file,
                        enable_vad=True,
                        debug_output=False  # å…³é—­è°ƒè¯•è¾“å‡º
                    )
                    
                    print("âœ… å½•éŸ³å®Œæˆï¼Œæ­£åœ¨å¤„ç†...")
                    
                    # å¿«é€Ÿè¯­éŸ³è¯†åˆ«
                    user_input = self._fast_speech_to_text(audio_file)
                    
                    if not user_input or user_input.strip() == "":
                        print("âš ï¸ æœªè¯†åˆ«åˆ°æœ‰æ•ˆè¯­éŸ³ï¼Œè¯·é‡è¯•")
                        continue
                    
                    print(f"ğŸ‘¤ [è¯†åˆ«ç»“æœ]: {user_input}")
                    
                    # æ£€æŸ¥æ˜¯å¦ä¸ºç»“æŸæŒ‡ä»¤
                    goodbye_patterns = ['å†è§', 'bye', 'goodbye', 'æ‹œæ‹œ', '88', 'ç»“æŸå¯¹è¯']
                    if any(pattern in user_input.lower() for pattern in goodbye_patterns):
                        print("ğŸ‘‹ æ£€æµ‹åˆ°å‘Šåˆ«è¯­ï¼Œå‡†å¤‡ç»“æŸå¯¹è¯")
                        break
                    
                    # è·å–æ™ºèƒ½ä½“å›å¤ï¼ˆä½¿ç”¨å¿«é€Ÿè®°å¿†ç³»ç»Ÿï¼‰
                    response = self.memory_agent.chat(user_input)
                    print(f"ğŸ¤– [æ™ºèƒ½ä½“]: {response}")
                    
                    # TTSè¯­éŸ³æ’­æ”¾å›å¤
                    self._fast_text_to_speech(response)
                    
                    # æ‰¹é‡æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    self._add_temp_file_for_cleanup(audio_file)
                    
                except KeyboardInterrupt:
                    print("\nâš ï¸ ç”¨æˆ·ä¸­æ–­å¯¹è¯")
                    break
                except Exception as e:
                    if not should_skip_check('detailed_validation'):
                        print(f"âŒ å¯¹è¯è½®æ¬¡å‡ºé”™: {e}")
                    continue
            
            # ç»“æŸå¯¹è¯
            self.memory_agent.end_conversation()
            print("ğŸ‘‹ è¯­éŸ³å¯¹è¯ç»“æŸ")
            
        except Exception as e:
            if not should_skip_check('detailed_validation'):
                print(f"âŒ è¯­éŸ³å¯¹è¯è¿‡ç¨‹å‡ºé”™: {e}")
        finally:
            # åœæ­¢äººè„¸è·Ÿè¸ªçº¿ç¨‹
            self._stop_face_tracking_thread()
            self.state = AgentState.LISTENING
            # æ‰¹é‡æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            self._batch_cleanup_temp_files()
    
    @PerformanceOptimizer.timing_decorator("fast_speech_to_text")
    def _fast_speech_to_text(self, audio_file: str) -> str:
        """å¿«é€Ÿè¯­éŸ³è½¬æ–‡å­—ï¼ˆå‡å°‘æ£€æŸ¥å’Œä¼˜åŒ–å¤„ç†ï¼‰"""
        try:
            # è·³è¿‡è¯¦ç»†çš„æ–‡ä»¶æ£€æŸ¥
            if not should_skip_check('audio_file_size'):
                file_size = os.path.getsize(audio_file)
                if file_size < 1000:
                    return ""
            
            # ä½¿ç”¨ç¼“å­˜æ£€æŸ¥
            if fast_config.FAST_MODE.get('cache_enabled', False):
                cache_key = f"asr_{fast_hash(audio_file)}_{os.path.getmtime(audio_file)}"
                cached_result = self._audio_cache.get(cache_key)
                if cached_result is not None:
                    return cached_result
            
            # ä½¿ç”¨ç§‘å¤§è®¯é£ASRè¿›è¡Œè¯­éŸ³è¯†åˆ«
            asr_result_file = f"/tmp/asr_result_{int(time.time())}.txt"
            
            asr = SparkASR(
                app_id=self.config.asr_app_id,
                api_key=self.config.asr_api_key,
                api_secret=self.config.asr_api_secret,
                audio_file=audio_file,
                output_file=asr_result_file
            )
            
            # æ‰§è¡Œè¯­éŸ³è¯†åˆ«ï¼ˆä½¿ç”¨è¶…æ—¶ï¼‰
            asr.recognize()
            
            # è¯»å–è¯†åˆ«ç»“æœ
            result = ""
            if os.path.exists(asr_result_file):
                try:
                    with open(asr_result_file, 'r', encoding='utf-8') as f:
                        result = f.read().strip()
                    
                    # æ·»åŠ åˆ°æ¸…ç†åˆ—è¡¨
                    self._add_temp_file_for_cleanup(asr_result_file)
                    
                    # ç¼“å­˜ç»“æœ
                    if fast_config.FAST_MODE.get('cache_enabled', False) and result:
                        self._audio_cache.put(cache_key, result)
                        
                except Exception:
                    pass  # ç®€åŒ–é”™è¯¯å¤„ç†
            
            return result
            
        except Exception:
            return ""  # ç®€åŒ–é”™è¯¯å¤„ç†
    
    @PerformanceOptimizer.timing_decorator("fast_text_to_speech")
    def _fast_text_to_speech(self, text: str):
        """å¿«é€Ÿæ–‡å­—è½¬è¯­éŸ³å¹¶æ’­æ”¾"""
        try:
            # ä½¿ç”¨ç¼“å­˜æ£€æŸ¥
            if fast_config.FAST_MODE.get('cache_enabled', False):
                cache_key = f"tts_{fast_hash(text)}"
                cached_audio = self._audio_cache.get(cache_key)
                if cached_audio is not None:
                    # æ’­æ”¾ç¼“å­˜çš„éŸ³é¢‘
                    return
            
            # å°†æ–‡æœ¬å†™å…¥æ–‡ä»¶
            with open(self.config.tts_text_file, 'w', encoding='utf-8') as f:
                f.write(text)
            
            # ç”Ÿæˆè¯­éŸ³
            self.voice_cloner.speak()
            
            # æ’­æ”¾è¯­éŸ³
            self.voice_cloner.play_audio()
            
        except Exception:
            pass  # ç®€åŒ–é”™è¯¯å¤„ç†
    
    def _add_temp_file_for_cleanup(self, file_path: str):
        """æ·»åŠ ä¸´æ—¶æ–‡ä»¶åˆ°æ‰¹é‡æ¸…ç†åˆ—è¡¨"""
        self._temp_files.append(file_path)
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ‰¹é‡æ¸…ç†
        if len(self._temp_files) >= get_batch_size('file_cleanup'):
            self._batch_cleanup_temp_files()
    
    def _batch_cleanup_temp_files(self):
        """æ‰¹é‡æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        for file_path in self._temp_files:
            try:
                if os.path.exists(file_path):
                    os.remove(file_path)
            except:
                pass  # å¿½ç•¥åˆ é™¤é”™è¯¯
        
        self._temp_files.clear()
    
    # ç®€åŒ–çš„å·¥å…·æ‰§è¡Œæ–¹æ³•
    def _execute_face_recognition(self):
        """æ‰§è¡Œäººè„¸è¯†åˆ«ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰"""
        try:
            os.system("/home/xuanwu/miniconda3/envs/face/bin/python /home/xuanwu/haven_ws/src/myTools/recognize.py")
        except:
            pass
    
    def _execute_face_registration(self, user_name: str):
        """æ‰§è¡Œäººè„¸æ³¨å†Œï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰"""
        try:
            command = f"/home/xuanwu/miniconda3/envs/face/bin/python /home/xuanwu/haven_ws/src/myTools/register.py {user_name}"
            os.system(command)
        except:
            pass
    
    def _execute_move_forward(self, distance: float):
        """æ‰§è¡Œå‰è¿›ç§»åŠ¨"""
        if not self.move_connected:
            return
        try:
            self.move_controller.move_linear_for_distance(distance)
        except:
            pass
    
    def _execute_move_backward(self, distance: float):
        """æ‰§è¡Œåé€€ç§»åŠ¨"""
        if not self.move_connected:
            return
        try:
            self.move_controller.move_linear_for_distance(-distance)
        except:
            pass
    
    def _execute_turn_left(self, angle: float):
        """æ‰§è¡Œå·¦è½¬"""
        if not self.move_connected:
            return
        try:
            self.move_controller.move_angular_for_angle(angle)
        except:
            pass
    
    def _execute_turn_right(self, angle: float):
        """æ‰§è¡Œå³è½¬"""
        if not self.move_connected:
            return
        try:
            self.move_controller.move_angular_for_angle(-angle)
        except:
            pass
    
    def _execute_move_to_location(self, location_name: str):
        """æ‰§è¡Œç§»åŠ¨åˆ°æŒ‡å®šä½ç½®"""
        if not self.move_connected:
            return
        try:
            self.move_controller.move_to_marker(location_name)
        except:
            pass
    
    def _execute_cancel_move(self):
        """æ‰§è¡Œå–æ¶ˆç§»åŠ¨"""
        if not self.move_connected:
            return
        try:
            self.move_controller.cancel_move()
        except:
            pass
    
    def _start_face_tracking_thread(self):
        """å¯åŠ¨äººè„¸è·Ÿè¸ªçº¿ç¨‹ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰"""
        self.face_tracking_active = True
        self.face_tracking_thread = threading.Thread(
            target=self._face_tracking_loop, 
            daemon=True
        )
        self.face_tracking_thread.start()
    
    def _stop_face_tracking_thread(self):
        """åœæ­¢äººè„¸è·Ÿè¸ªçº¿ç¨‹"""
        if hasattr(self, 'face_tracking_active'):
            self.face_tracking_active = False
    
    def _face_tracking_loop(self):
        """äººè„¸è·Ÿè¸ªå¾ªç¯ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰"""
        try:
            while (hasattr(self, 'face_tracking_active') and 
                   self.face_tracking_active and 
                   self.state == AgentState.CHATTING):
                
                # è·å–å½“å‰è¯†åˆ«ç»“æœ
                recognized_name, middle_pixel = self.face_system.recognize_person()
                
                # å¦‚æœè¯†åˆ«åˆ°ç”¨æˆ·ï¼Œè¿›è¡Œè·Ÿè¸ª
                if recognized_name and recognized_name != "Unknown":
                    self.face_system.follow_person(middle_pixel, recognized_name)
                
                time.sleep(0.8)  # å‡å°‘è·Ÿè¸ªé¢‘ç‡
                
        except Exception:
            pass  # ç®€åŒ–é”™è¯¯å¤„ç†
    
    def get_current_state(self) -> Dict:
        """è·å–å½“å‰çŠ¶æ€ä¿¡æ¯"""
        return {
            "state": self.state.value,
            "current_user": self.current_user,
            "current_confidence": self.current_confidence,
            "is_running": self.is_running,
            "last_recognition_time": self.last_recognition_time,
            "performance_stats": PerformanceOptimizer.get_performance_stats(),
            "cache_stats": {
                "audio_cache_size": self._audio_cache.size(),
                "response_cache_size": self._response_cache.size(),
                "temp_files_count": len(self._temp_files)
            }
        }
    
    def cleanup(self):
        """æ¸…ç†èµ„æºï¼ˆå¿«é€Ÿç‰ˆæœ¬ï¼‰"""
        # åœæ­¢åå°è¯†åˆ«
        self.is_running = False
        
        # ç»“æŸå½“å‰å¯¹è¯
        if self.state == AgentState.CHATTING:
            self.memory_agent.end_conversation()
        
        # æ¸…ç†é¢éƒ¨è¯†åˆ«ç³»ç»Ÿ
        self.face_system.cleanup()
        
        # æ–­å¼€æœºå™¨äººè¿æ¥
        if self.move_connected:
            self.move_controller.disconnect()
            self.move_connected = False
        
        # æ‰¹é‡æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        self._batch_cleanup_temp_files()
        
        # æ¸…ç†ç¼“å­˜
        self._audio_cache.clear()
        self._response_cache.clear()
        global_cache.clear()

# ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•å‡½æ•°
def create_fast_config() -> FastSuperAgentConfig:
    """åˆ›å»ºå¿«é€Ÿé…ç½®"""
    face_config = FaceRecognitionConfig(
        service_url="http://localhost:5001",
        recognition_threshold=0.6,
        left_threshold=300,
        right_threshold=340,
        follow_delta_angle=15
    )
    
    return FastSuperAgentConfig(
        face_config=face_config,
        deepseek_api_key="sk-fdabadb2973b4795b2444da60e75152f",
        deepseek_base_url="https://api.deepseek.com",
        memory_file_path="/home/xuanwu/haven_ws/demos/data/memory_tree.json",
        
        # TTSé…ç½®
        tts_voice_name="default",
        tts_config_path="/home/xuanwu/haven_ws/config/voices.json",
        tts_text_file="/tmp/tts_text.txt",
        tts_audio_file="/tmp/tts_output.wav",
        
        # æœºå™¨äººç§»åŠ¨é…ç½®
        robot_host="192.168.10.10",
        robot_port=31001,
        
        # ä¼˜åŒ–çš„é…ç½®
        search_angle_range=(-45, 45),  # å‡å°‘æœç´¢èŒƒå›´
        search_step=45,                # å¢åŠ æ­¥é•¿
        search_delay=fast_config.FACE_RECOGNITION_CONFIG['search_stabilization_time'],
        recognition_confidence_threshold=0.6,
        continuous_scan_interval=0.3,   # å‡å°‘æ‰«æé—´éš”
        unknown_user_timeout=3.0        # å‡å°‘è¶…æ—¶æ—¶é—´
    )

def main():
    """ä¸»å‡½æ•° - å¿«é€Ÿè¯­éŸ³å”¤é†’æ¨¡å¼"""
    print("ğŸš€ å¯åŠ¨å¿«é€Ÿè¶…çº§æ™ºèƒ½ä½“ - è¯­éŸ³å”¤é†’æ¨¡å¼")
    
    # åˆ›å»ºå¿«é€Ÿé…ç½®
    config = create_fast_config()
    
    # åˆ›å»ºå¿«é€Ÿè¶…çº§æ™ºèƒ½ä½“
    agent = FastSuperIntelligentAgent(config)
    
    try:
        # åˆå§‹åŒ–ç³»ç»Ÿ
        if not agent.initialize():
            print("âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥")
            return
        
        print("\n" + "="*60)
        print("ğŸ¤– å¿«é€Ÿè¶…çº§æ™ºèƒ½ä½“å·²å¯åŠ¨")
        print("ğŸ§ ç³»ç»Ÿå°†æŒç»­ç›‘å¬è¯­éŸ³å”¤é†’è¯")
        print("ğŸ’¬ è¯·è¯´ 'å°åŠ©å°åŠ©' æ¥å”¤é†’æ™ºèƒ½ä½“")
        print("âš¡ æ€§èƒ½ä¼˜åŒ–å·²å¯ç”¨ - å“åº”æ›´å¿«é€Ÿ")
        print("="*60 + "\n")
        
        # å¯åŠ¨è¯­éŸ³å”¤é†’ç›‘å¬
        agent.start_voice_wake_listening()
        
    except KeyboardInterrupt:
        print("\nğŸ›‘ æ£€æµ‹åˆ°ä¸­æ–­ä¿¡å·")
    except Exception as e:
        print(f"âŒ ç³»ç»Ÿè¿è¡Œé”™è¯¯: {e}")
    finally:
        # æ¸…ç†èµ„æº
        agent.cleanup()
        
        # æ‰“å°æ€§èƒ½ç»Ÿè®¡
        stats = agent.get_current_state()
        print("\nğŸ“Š æ€§èƒ½ç»Ÿè®¡:")
        print(f"  ç¼“å­˜å‘½ä¸­: {stats['cache_stats']}")
        print(f"  æ€§èƒ½æ•°æ®: {len(stats['performance_stats'])} é¡¹")
        
        print("ğŸ‘‹ å¿«é€Ÿè¶…çº§æ™ºèƒ½ä½“å·²å…³é—­")

if __name__ == "__main__":
    main()